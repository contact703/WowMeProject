'use client'

import { useState, useRef, useEffect } from 'react'
import { MicIcon } from './Icons'

interface AudioRecorderProps {
  onTranscriptionComplete: (text: string, audioBlob: Blob) => void
  language: string
}

export default function AudioRecorder({ onTranscriptionComplete, language }: AudioRecorderProps) {
  const [isRecording, setIsRecording] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const [recordingTime, setRecordingTime] = useState(0)
  const [error, setError] = useState<string | null>(null)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const chunksRef = useRef<Blob[]>([])
  const timerRef = useRef<NodeJS.Timeout | null>(null)

  useEffect(() => {
    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current)
      }
    }
  }, [])

  const startRecording = async () => {
    try {
      setError(null)
      console.log('ðŸŽ¤ Requesting microphone access...')
      
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      console.log('âœ… Microphone access granted')
      
      const mediaRecorder = new MediaRecorder(stream)
      mediaRecorderRef.current = mediaRecorder
      chunksRef.current = []
      setRecordingTime(0)

      // Start timer
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1)
      }, 1000)

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          chunksRef.current.push(e.data)
          console.log('ðŸ“¦ Audio chunk received:', e.data.size, 'bytes')
        }
      }

      mediaRecorder.onstop = async () => {
        console.log('ðŸ›‘ Recording stopped')
        
        if (timerRef.current) {
          clearInterval(timerRef.current)
        }
        
        stream.getTracks().forEach(track => {
          track.stop()
          console.log('ðŸ”‡ Microphone track stopped')
        })
        
        const audioBlob = new Blob(chunksRef.current, { type: 'audio/webm' })
        console.log('ðŸ“¦ Audio blob created:', audioBlob.size, 'bytes')
        
        // Transcribe audio using Groq Whisper
        setIsProcessing(true)
        try {
          console.log('ðŸš€ Sending audio to transcription API...')
          
          const formData = new FormData()
          formData.append('audio', audioBlob, 'recording.webm')
          
          // Convert language code for Whisper API (pt-BR -> pt, etc)
          const whisperLanguage = language.split('-')[0]
          console.log('ðŸŒ Language:', language, 'â†’', whisperLanguage)
          formData.append('language', whisperLanguage)

          const response = await fetch('/api/transcribe', {
            method: 'POST',
            body: formData,
          })

          console.log('ðŸ“¡ API response status:', response.status)

          if (!response.ok) {
            const errorData = await response.json()
            console.error('âŒ Transcription failed:', errorData)
            throw new Error(errorData.error || 'Transcription failed')
          }

          const data = await response.json()
          console.log('âœ… Transcription successful:', data.text.substring(0, 100))
          
          onTranscriptionComplete(data.text, audioBlob)
          setError(null)
        } catch (error: any) {
          console.error('âŒ Transcription error:', error)
          setError(error.message || 'Failed to transcribe audio')
          alert(`Transcription failed: ${error.message}\n\nPlease try again or use text input.`)
        } finally {
          setIsProcessing(false)
        }
      }

      mediaRecorder.start()
      setIsRecording(true)
      console.log('ðŸŽ™ï¸ Recording started')
    } catch (error: any) {
      console.error('âŒ Error starting recording:', error)
      setError(error.message || 'Could not access microphone')
      alert(`Could not access microphone: ${error.message}\n\nPlease check permissions and try again.`)
    }
  }

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      console.log('â¹ï¸ Stopping recording...')
      mediaRecorderRef.current.stop()
      setIsRecording(false)
    }
  }

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60)
    const secs = seconds % 60
    return `${mins}:${secs.toString().padStart(2, '0')}`
  }

  return (
    <div className="flex flex-col items-center gap-4">
      {error && (
        <div className="bg-red-500/20 border border-red-500 text-red-300 px-4 py-2 rounded-lg text-sm">
          {error}
        </div>
      )}
      
      {!isRecording && !isProcessing && (
        <button
          onClick={startRecording}
          className="flex items-center gap-2 px-6 py-3 bg-gradient-to-r from-red-500 to-red-500 text-white rounded-lg hover:from-red-600 hover:to-red-600 transition-all shadow-lg"
        >
          <MicIcon size={20} />
          <span>Record Audio</span>
        </button>
      )}

      {isRecording && (
        <div className="flex flex-col items-center gap-3">
          <div className="flex items-center gap-3 bg-red-500/20 px-6 py-3 rounded-lg border border-red-500 animate-pulse">
            <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse"></div>
            <span className="text-red-300 font-mono text-lg">{formatTime(recordingTime)}</span>
          </div>
          
          <button
            onClick={stopRecording}
            className="flex items-center gap-2 px-6 py-3 bg-red-500 text-white rounded-lg hover:bg-red-600 transition-all shadow-lg"
          >
            <svg className="w-5 h-5" fill="currentColor" viewBox="0 0 20 20">
              <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8 7a1 1 0 00-1 1v4a1 1 0 001 1h4a1 1 0 001-1V8a1 1 0 00-1-1H8z" clipRule="evenodd" />
            </svg>
            <span>Stop Recording</span>
          </button>
        </div>
      )}

      {isProcessing && (
        <div className="flex flex-col items-center gap-3">
          <div className="flex items-center gap-2 text-red-400">
            <svg className="animate-spin h-6 w-6" fill="none" viewBox="0 0 24 24">
              <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
              <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
            </svg>
            <span className="font-medium">Processing audio...</span>
          </div>
          <p className="text-sm text-gray-400">This may take a few seconds</p>
        </div>
      )}
    </div>
  )
}

